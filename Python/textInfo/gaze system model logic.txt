Overview
This function analyzes gaze direction using facial landmarks from MediaPipe's face detection model.
It computes 3D head pose estimation to determine whether the subject is looking left, right, up, down, or forward.
The system tracks gaze behavior for 20 frames and maintains a count of gaze direction occurrences.

Face Landmark Extraction
Landmarks used: [33, 263, 1, 61, 291, 199] (Key facial points).
If multiple faces are detected, it iterates through them.
Extracts 2D coordinates (for screen-space mapping) and 3D coordinates (for depth estimation).
Nose landmark (idx == 1) is used as a reference for 3D positioning.

Head Pose Estimation
Uses solvePnP (Perspective-n-Point) algorithm to estimate rotation and translation vectors.
Converts the rotation vector into Euler angles:
x-angle → Up/Down movement.
y-angle → Left/Right movement.

Camera parameters:
Focal length = image_width * 1

Distortion matrix: Zeroes (assuming no lens distortion).

Gaze Classification
Based on head angles:
y < -10 → Looking Left (Text: "Looking left? Look forward!")
y > 10 → Looking Right (Text: "Looking right? Look forward!")
x < -10 → Looking Down (Text: "Looking down? Look forward!")
x > 10 → Looking Up (Text: "Looking up? Look forward!")
Otherwise → Looking Forward (Normal state).

Tracking Gaze Behavior
Gaze status is updated every frame.
Dictionary self.gaze_tracking stores:
First value → Count of frames a gaze has been detected.
Second value → Count of frames the gaze has been missing.

If a gaze is detected:
If previously seen → Increment detection count & reset missing count.
If new → Initialize with (1, 0).
If a gaze is missing:
Increment its missing count.
If missing for 20 frames, it is removed.

Gaze Confirmation Logic
An object must appear for 10 frames before updating self.gaze_result[gaze].
Prevents false positives due to temporary head movements.
self.prev_gaze keeps track of the last detected gaze.

Handling Face Obstructions
If no face landmarks are detected:
Displays: "Something is obstructing the face"
Tracks the "Obstruct" label similarly to other gaze directions.
If obstruction persists for 20 frames, it is removed from tracking.

Displaying Results
Gaze direction text is displayed in red (0, 0, 255) on the face.
cv.putText() is used to overlay detection results.

Why 20 Frames?
The camera operates at 10 FPS:
1 second = 10 frames
2 seconds = 20 frames
This prevents erratic tracking due to rapid head movements.
